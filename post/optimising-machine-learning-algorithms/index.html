<!DOCTYPE html>
<html lang="en-gb">
<head>

    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    


    
    
        
        <meta name="twitter:card" content="summary_large_image"/>
        <meta name="twitter:image" content="http://www.jamesbowman.me//post/optimising-algorithms.jpg"/>
    
    



<meta name="twitter:title" content="Optimising algorithms in Go for machine learning"/>
<meta name="twitter:description" content="Benchmarking and optimising algorithms in Golang for machine learning and large data sets"/>
<meta name="twitter:site" content="@jamesebowman"/>



  	<meta property="og:title" content="Optimising algorithms in Go for machine learning &middot; James Bowman" />
  	<meta property="og:site_name" content="James Bowman" />
  	<meta property="og:url" content="http://www.jamesbowman.me/post/optimising-machine-learning-algorithms/" />

    
    <meta property="og:description" content="Benchmarking and optimising algorithms in Golang for machine learning and large data sets" />
  	<meta property="og:type" content="article" />
    
    <meta property="og:image" content="http://www.jamesbowman.me//post/optimising-algorithms.jpg" />
    
    <meta property="article:published_time" content="2017-03-31T16:31:29&#43;01:00" />

    
    <meta property="article:tag" content="development" />
    
    <meta property="article:tag" content="machine learning" />
    
    <meta property="article:tag" content="go" />
    
    <meta property="article:tag" content="algorithms" />
    
    <meta property="article:tag" content="data structures" />
    
    

    
  
    <title>Optimising algorithms in Go for machine learning &middot; James Bowman</title>

    
    <meta name="description" content="Benchmarking and optimising algorithms in Golang for machine learning and large data sets" />
    

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="shortcut icon" href="http://www.jamesbowman.me/images/favicon.ico">
	  <link rel="apple-touch-icon" href="http://www.jamesbowman.me/images/apple-touch-icon.png" />

    <link rel="stylesheet" type="text/css" href="http://www.jamesbowman.me/css/screen.css" />
    <link rel="stylesheet" type="text/css" href="http://www.jamesbowman.me/css/nav.css" />
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400|Inconsolata" />


    
        <link href="http://feeds.jamesbowman.me/jamesbowman/blog" rel="alternate" type="application/rss+xml" title="James Bowman" />
    
    <meta name="generator" content="Hugo 0.18" />

    <link rel="canonical" href="http://www.jamesbowman.me/post/optimising-machine-learning-algorithms/" />

    
      
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "James Bowman",
        "logo": "http://www.jamesbowman.me/selfportraitBWcirc.png"
    },
    "author": {
        "@type": "Person",
        "name": "James Bowman",
        
        "image": {
            "@type": "ImageObject",
            "url": "http://www.jamesbowman.me/selfportraitBWcirc.png",
            "width": 250,
            "height": 250
        }, 
        
        "url": "http://www.jamesbowman.me",
        "sameAs": [
            
            
             "https://plus.google.com/+JamesBowman1978",
             "https://github.com/james-bowman",
             
             "https://uk.linkedin.com/in/jamesedwardbowman",
             "https://twitter.com/JameseBowman"
            
        ],
        "description": "I love coding in Go, microservices, continuous delivery and DevOps. I am fascinated by coaching, learning, people's behaviour and organisational change."
        
    },
    "headline": "Optimising algorithms in Go for machine learning",
    "name": "Optimising algorithms in Go for machine learning",
    "wordCount":  1654 ,
    "timeRequired": "PT8M",
    "inLanguage": {
      "@type": "Language",
      "alternateName": "en"
    },
    "url": "http://www.jamesbowman.me/post/optimising-machine-learning-algorithms/",
    "datePublished": "2017-03-31T16:31Z",
    "dateModified": "2017-03-31T16:31Z",
    
    "image": {
        "@type": "ImageObject",
        "url": "http://www.jamesbowman.me//post/optimising-algorithms.jpg",
        "width": 3000,
        "height": 1445
    },
    
    
    "keywords": "development, machine learning, go, algorithms, data structures",
    "description": "Benchmarking and optimising algorithms in Golang for machine learning and large data sets",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://www.jamesbowman.me/post/optimising-machine-learning-algorithms/"
    }
}
    </script>
    


    

    

    
        
<script>
(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-MRG66N');</script>



    
</head>
<body class="nav-closed">

  
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MRG66N"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
        
        
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/">Blog</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/post">Archive</a>
            </li>
        
            
            <li class="nav-opened" role="presentation">
            	<a href="/about-james-bowman">About me</a>
            </li>
        
    </ul>
    
    
    <a class="subscribe-button icon-feed" href="http://feeds.jamesbowman.me/jamesbowman/blog">Subscribe</a> </div>
    
</div>
<span class="nav-cover"></span>


 <div class="site-wrapper">




  
  <header class="main-header post-head" style="background-image: url(http://www.jamesbowman.me//post/optimising-algorithms.jpg)">
  
  <nav class="main-nav overlay clearfix">


  <a class="menu-button" style="float: left;" href="http://www.jamesbowman.me/"><span class="icon-home"/><span class="word">&lt;&nbsp; Home</span></a>
  
      <a class="menu-button" href="#"><span class="burger">&#9776;</span><span class="word">Menu</span></a>
  
  </nav>
</header>



<main class="content" role="main">




  <article class="post post">

    <header class="post-header">
        <h1 class="post-title">Optimising algorithms in Go for machine learning</h1>
        <small>Benchmarking and optimising algorithms in Golang for machine learning and large data sets</small>

        <section class="post-meta">
        
          <time class="post-date" datetime="2017-03-31T16:31:29&#43;01:00">
            Mar 31, 2017
          </time>
        
         
          <span class="post-tag small"><a href="http://www.jamesbowman.me/tags/development/">#development</a></span>
         
          <span class="post-tag small"><a href="http://www.jamesbowman.me/tags/machine-learning/">#machine learning</a></span>
         
          <span class="post-tag small"><a href="http://www.jamesbowman.me/tags/go/">#go</a></span>
         
          <span class="post-tag small"><a href="http://www.jamesbowman.me/tags/algorithms/">#algorithms</a></span>
         
          <span class="post-tag small"><a href="http://www.jamesbowman.me/tags/data-structures/">#data structures</a></span>
         
        </section>
    </header>

    <section class="post-content">
      

<p>In my <a href="http://www.jamesbowman.me/post/semantic-analysis-of-webpages-with-machine-learning-in-go/">last blog post I walked through the use of machine learning algorithms in Golang to analyse the latent semantic meaning of documents</a>.  These algorithms, like many others in data science, rely on linear algebra and vector space analysis.  By their nature, they often have to deal with large data sets, so any inefficiencies in the data structures used or algorithms themselves can result in a large impact on overall performance and/or memory usage.  Inefficiencies that are negligable when working with small data sets can have a huge cost applied across extremely large datasets.  As memory is a constrained resource, this could end up limiting the size of data sets that may be processed (certainly without having to resort to persistent storage and/or alternative algorithms) or the types of algorithms used.  To this end, I decided to see if I could optimise the algorithms I used to consume less memory and improve processing performance without sacrificing too much functionality or accuracy.  This is the first in a series of articles sharing my experiences benchmarking and optimising the algorithms and data structures used whilst building out the <a href="http://github.com/james-bowman/nlp">nlp project</a>.</p>

<h2 id="optimisation-of-the-tf-idf-transform">Optimisation of the TF-IDF transform</h2>

<p>As can be seen in the code snippet below, the TF-IDF transformer maintains a matrix internally,which is used to transform matrices containing raw term freqencies(tf) into weighted tf-idf values (term frequency - inverse document frequencies).  The transform is simply multiplied by the input tf matrix to produce the tf-idf matrix.  Please refer to the <a href="http://www.jamesbowman.me/post/semantic-analysis-of-webpages-with-machine-learning-in-go/">previous blog post for a more in depth description of TF-IDF</a>.</p>

<p>The transform matrix is a <a href="https://en.wikipedia.org/wiki/Diagonal_matrix#Symmetric_diagonal_matrices">symmetric diagonal matrix</a> and so will have as many rows and columns as there were unique terms/words in the training data set.  For a representative sample of 3000 articles from internet sites, I found the number of unique terms was typically around 30,000 which would require a 30,000 x 30,000 transform matrix.  Therefore the TF-IDF transform is a 30,000 x 30,000 matrix with elements of type float64 which will require approximately 7GB of memory.  Ironically the majority of elements within this matrix will contain zeros, in fact, only values along the diagonal (from top left to bottom right) will be non-zero.  There is clearly scope to optimise its memory use.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #0000ff">type</span> TfidfTransformer1 <span style="color: #0000ff">struct</span> {
    transform *mat64.Dense
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer1) Fit(mat mat64.Matrix) Transformer {
    m, n := mat.Dims()

    <span style="color: #008000">// build a diagonal matrix from array of term weighting values for subsequent</span>
    <span style="color: #008000">// multiplication with term document matrics</span>
    t.transform = mat64.NewDense(m, m, <span style="color: #0000ff">nil</span>)

    <span style="color: #0000ff">for</span> i := 0; i &lt; m; i++ {
        df := 0
        <span style="color: #0000ff">for</span> j := 0; j &lt; n; j++ {
            <span style="color: #0000ff">if</span> mat.At(i, j) != 0 {
                df++
            }
        }
        idf := math.Log(float64(1+n) / float64(1+df))
        t.transform.Set(i, i, idf)
    }

    <span style="color: #0000ff">return</span> t
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer1) Transform(mat mat64.Matrix) (*mat64.Dense, <span style="color: #2b91af">error</span>) {
    m, n := mat.Dims()
    product := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)

    <span style="color: #008000">// simply multiply the matrix by our idf transform (the diagonal matrix of term weights)</span>
    product.Product(t.transform, mat)

    <span style="color: #0000ff">return</span> product, <span style="color: #0000ff">nil</span>
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer1) FitTransform(mat mat64.Matrix) (*mat64.Dense, <span style="color: #2b91af">error</span>) {
    <span style="color: #0000ff">return</span> t.Fit(mat).Transform(mat)
}
</pre></div>

<p>My initial thought was to use a sparse matrix instead of the dense matrix implementation I was using.  A sparse matrix could more efficiently store a matrix mostly comprised of zeros, storing only the non-zero values.  Unfortunately the gonum matrix library I am using does not currently have a sparse matrix implementation.</p>

<p>As an alternative approach, I considered simply storing the non-zero idf (term weights) values as an array of float64 values and then individually multiplying every element within the input raw tf matrix by its corresponding term weight from the array.  The code for this implementation called TfidfTransformer2 is shown below.  Note the differences in the <code>Fit()</code> method where we no longer build a symmetric diagonal transform matrix and simply keep the array of term weights.  Also, the <code>Transform()</code> method is now changed to simply iterate over every matrix element and multiply its value by the corresponding term weight from the array.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #0000ff">type</span> TfidfTransformer2 <span style="color: #0000ff">struct</span> {
    weights []<span style="color: #2b91af">float64</span>
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer2) Fit(mat mat64.Matrix) Transformer {
    m, n := mat.Dims()

    <span style="color: #008000">// simply capture term weights as an array</span>
    t.weights = make([]<span style="color: #2b91af">float64</span>, m)

    <span style="color: #0000ff">for</span> i := 0; i &lt; m; i++ {
        df := 0
        <span style="color: #0000ff">for</span> j := 0; j &lt; n; j++ {
            <span style="color: #0000ff">if</span> mat.At(i, j) != 0 {
                df++
            }
        }
        idf := math.Log(float64(1+n) / float64(1+df))
        t.weights[i] = idf
    }

    <span style="color: #0000ff">return</span> t
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer2) Transform(mat mat64.Matrix) (*mat64.Dense, <span style="color: #2b91af">error</span>) {
    m, n := mat.Dims()
    product := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)

    <span style="color: #008000">// iterate over every element of the matrix in turn and </span>
    <span style="color: #008000">// multiply the element value by the corresponding term weight</span>
    <span style="color: #0000ff">for</span> i := 0; i &lt; m; i++ {
        <span style="color: #0000ff">for</span> j := 0; j &lt; n; j++ {
            product.Set(i, j, mat.At(i, j) * t.weights[i])
        }
    }

    <span style="color: #0000ff">return</span> product, <span style="color: #0000ff">nil</span>
}

<span style="color: #0000ff">func</span> (t *TfidfTransformer2) FitTransform(mat mat64.Matrix) (*mat64.Dense, <span style="color: #2b91af">error</span>) {
    <span style="color: #0000ff">return</span> t.Fit(mat).Transform(mat)
}
</pre></div>

<p>This second approach would be considerably more memory efficient but I had some concerns over performance, specifically how well iterating over every matrix element, using nested loops, outside of the heavily optimised LAPACK/BLAS libraries would perform.</p>

<p>Then I found a matrix <code>Apply()</code> method within the gonum/mat64 library that would apply a function to every element within the matrix.  Unlike the nested loop approach, this would allow the optimised LAPACK/BLAS libraries to handle the iteration so should theoretically be more performant.  This implementation would be identical to the <code>TfidfTransformer2</code> above save for the <code>Transform()</code> method where the matrix <code>Apply()</code> method is used instead of nested loops.  The differing <code>Transform()</code> method is shown below.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #0000ff">func</span> (t *TfidfTransformer3) Transform(mat mat64.Matrix) (*mat64.Dense, <span style="color: #2b91af">error</span>) {
    m, n := mat.Dims()
    product := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)

    <span style="color: #008000">// apply a function to every element of the matrix in turn which</span>
    <span style="color: #008000">// multiplies the element value by the corresponding term weight</span>
    product.Apply(<span style="color: #0000ff">func</span>(i, j <span style="color: #2b91af">int</span>, v <span style="color: #2b91af">float64</span>) <span style="color: #2b91af">float64</span> {
        <span style="color: #0000ff">return</span> (v * t.weights[i])
    }, mat)

    <span style="color: #0000ff">return</span> product, <span style="color: #0000ff">nil</span>
}
</pre></div>

<h3 id="benchmarks">Benchmarks</h3>

<p>To confirm our hypothesis that the new implementations will outperform the current matrix transform based implementation we will run some benchmarks using the inbuilt benchmark functionality inside Go&rsquo;s <code>testing</code> package.</p>

<p>Implementing a benchmark in Go is much the same as implementing a test except the function name is prefixed with <code>Benchmark</code> rather than <code>Test</code>.  Here are separate benchmark implementations for the <code>Fit()</code>, <code>Transform()</code> and <code>FitTransform()</code> methods exercised for each of the 3 algorithm implementations.  As the <code>Fit()</code> method is identical between implementation 2 (TfidfTransformer2) and 3 (TfidfTransformer3) I have not bothered to benchmark both instead just benchmarking the <code>Fit()</code> method from implementation 2.</p>
<div class="highlight" style="background: #ffffff"><pre style="line-height: 125%"><span></span><span style="color: #0000ff">func</span> benchmarkFit(t Transformer, m, n <span style="color: #2b91af">int</span>, b *testing.B) {
    mat := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)

    b.ResetTimer()
    <span style="color: #0000ff">for</span> n := 0; n &lt; b.N; n++ {
        t.Fit(mat)
    }
}

<span style="color: #0000ff">func</span> benchmarkFitTransform(t Transformer, m, n <span style="color: #2b91af">int</span>, b *testing.B) {
    mat := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)

    b.ResetTimer()
    <span style="color: #0000ff">for</span> n := 0; n &lt; b.N; n++ {
        t.FitTransform(mat)
    }
}

<span style="color: #0000ff">func</span> benchmarkTransform(t Transformer, m, n <span style="color: #2b91af">int</span>, b *testing.B) {
    mat := mat64.NewDense(m, n, <span style="color: #0000ff">nil</span>)
    t.Fit(mat)

    b.ResetTimer()
    <span style="color: #0000ff">for</span> n := 0; n &lt; b.N; n++ {
        t.Transform(mat)
    }
}

<span style="color: #0000ff">func</span> BenchmarkTFIDF1Fit30000x3000(b *testing.B) {
    benchmarkFit(&amp;TfidfTransformer1{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF1Transform30000x3000(b *testing.B) {
    benchmarkTransform(&amp;TfidfTransformer1{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF1FitTransform30000x3000(b *testing.B) {
    benchmarkFitTransform(&amp;TfidfTransformer1{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF2Fit30000x3000(b *testing.B) {
    benchmarkFit(&amp;TfidfTransformer2{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF2Transform30000x3000(b *testing.B) {
    benchmarkTransform(&amp;TfidfTransformer2{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF2FitTransform30000x3000(b *testing.B) {
    benchmarkFitTransform(&amp;TfidfTransformer2{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF3Transform30000x3000(b *testing.B) {
    benchmarkTransform(&amp;TfidfTransformer3{}, 30000, 3000, b)
}
<span style="color: #0000ff">func</span> BenchmarkTFIDF3FitTransform30000x3000(b *testing.B) {
    benchmarkFitTransform(&amp;TfidfTransformer3{}, 30000, 3000, b)
}
</pre></div>

<p>The benchmarks are run in the same way as tests except that the <code>-bench</code> option is used to express a regular expression matching the names of benchmark functions to run.  The regular expression <code>.</code> will match all benchmarks or as in the output below, <code>30000</code> will match and run all benchmarks with 30000 in the function name.  The <code>-benchmem</code> option will output memory allocations during the benchmark.  Here are the results of the benchmarks.</p>

<pre><code>$ go test -bench=30000 -benchmem
BenchmarkTFIDF1Fit30000x3000-4              1  6025208569 ns/op     7200006208 B/op     2 allocs/op
BenchmarkTFIDF1Transform30000x3000-4        1  41773814068 ns/op    720005856 B/op      18 allocs/op
BenchmarkTFIDF1FitTransform30000x3000-4     1  50079258438 ns/op    7920011056 B/op     11 allocs/op
BenchmarkTFIDF2Fit30000x3000-4              3  513875302 ns/op      245760 B/op         1 allocs/op
BenchmarkTFIDF2Transform30000x3000-4        1  1669005488 ns/op     720003136 B/op      2 allocs/op
BenchmarkTFIDF2FitTransform30000x3000-4     1  1472562820 ns/op     720250752 B/op      6 allocs/op
BenchmarkTFIDF3Transform30000x3000-4        2  884655455 ns/op      720003136 B/op      2 allocs/op
BenchmarkTFIDF3FitTransform30000x3000-4     1  1029592374 ns/op     720248896 B/op      3 allocs/op
PASS
ok      github.com/james-bowman/nlpbench    121.167s
</code></pre>

<p>From the benchmark results, we can see that as we expected, the <code>Fit()</code> method on the original implementation is allocating around 7 GB of memory (first row).  In comparison we can see that the new array based <code>Fit()</code> implementation is allocating around 250 KB.  This is a significant improvement, but how does the performance stack up?</p>

<p>According to the benchmark, the original implementation took 41773814068 nano seconds to perform the transform (second row).  Comparing this with 1669005488 nano seconds for the second nested loop based implementation (TfidfTransformer2 - row 5) would suggest the nested loop implementation is around 20 times faster.  If we further compare the third implementation (TfidfTransformer3), using the <code>Apply()</code> method and delegating the iteration over matrix elements down into the optimised LAPACK/BLAS libraries (row 7) we can see this is about twice as fast as the second implementation executing in around half the time.  As we would expect,memory usage is the same for both implementation 2 and 3.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>We started using a standard implementation of the TF-IDF algorithm (albeit using a Dense matrix implementation) and explored possible optimisations for memory usage.  We looked at 2 alternative methods and then tested our hypothesis using Go&rsquo;s inbuilt benchmark functionality.  The results showed that our optimisations materially improved not just memory consumption but also performance.  For a dataset with 30,000 terms across 3,000 documents, we showed the original implementation executed in around 41 seconds, consuming around 7 GB.  The new implementation processes the same dataset in just 0.8 seconds, consuming around 250 KB of memory.</p>

<p>All <a href="http://github.com/james-bowman/nlpbench">the Golang benchmarking code used in this article is on Github</a></p>


       
    <div class="index-content post">
        <div class="post-meta">
            <sub>
        Cover photo: <a href="https://www.flickr.com/photos/derekgavey/5528275910">Algorithmic Contaminations</a> by Derek Gavey, available under a <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a>
            </sub>
        </div>
    </div>
    
    </section>


  <footer class="post-footer">


    
    <figure class="author-image">
        <a class="img" href="http://www.jamesbowman.me/" style="background-image: url(http://www.jamesbowman.me/selfportraitBWcirc.png)"><span class="hidden">James Bowman's Picture</span></a>
    </figure>
    

    





<section class="author">
  <h4><a href="http://www.jamesbowman.me/">James Bowman</a></h4>
  
  <p>I love coding in Go, microservices, continuous delivery and DevOps. I am fascinated by coaching, learning, people&#39;s behaviour and organisational change.</p>
  
  <div class="author-meta">
    <span class="author-location icon-location">London, UK</span>
    <span class="author-link icon-link"><a href="http://www.jamesbowman.me">http://www.jamesbowman.me</a></span>
  </div>
</section>



    
<section class="share">
  <h4>Share this post</h4>
  <a class="icon-twitter" style="font-size: 1.4em" href="https://twitter.com/share?text=Optimising%20algorithms%20in%20Go%20for%20machine%20learning&nbsp;-&nbsp;James%20Bowman&amp;url=http%3a%2f%2fwww.jamesbowman.me%2fpost%2foptimising-machine-learning-algorithms%2f"
      onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
      <span class="hidden">Twitter</span>
  </a>
  <a class="icon-facebook" style="font-size: 1.4em" href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2fwww.jamesbowman.me%2fpost%2foptimising-machine-learning-algorithms%2f"
      onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
      <span class="hidden">Facebook</span>
  </a>
  <a class="icon-pinterest" style="font-size: 1.4em" href="http://pinterest.com/pin/create/button/?url=http%3a%2f%2fwww.jamesbowman.me%2fpost%2foptimising-machine-learning-algorithms%2f&amp;description=Optimising%20algorithms%20in%20Go%20for%20machine%20learning"
      onclick="window.open(this.href, 'pinterest-share','width=580,height=296');return false;">
      <span class="hidden">Pinterest</span>
  </a>
  <a class="icon-google-plus" style="font-size: 1.4em" href="https://plus.google.com/share?url=http%3a%2f%2fwww.jamesbowman.me%2fpost%2foptimising-machine-learning-algorithms%2f"
     onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
      <span class="hidden">Google+</span>
  </a>
</section>



    

<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'jamesebowman';
  var disqus_url = 'http:\/\/www.jamesbowman.me\/post\/optimising-machine-learning-algorithms\/';
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>




  </footer>
</article>

</main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="">James Bowman</a> All rights reserved 2017</section>
        
        <section class="poweredby">Proudly generated by <a class="icon-hugo" href="http://gohugo.io">HUGO</a>, with <a class="icon-theme" href="https://github.com/vjeantet/hugo-theme-casper">Casper</a> theme</section>
        
    </footer>
    </div>
    <script type="text/javascript" src="http://www.jamesbowman.me/js/jquery.js"></script>
    <script type="text/javascript" src="http://www.jamesbowman.me/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="http://www.jamesbowman.me/js/index.js"></script>
    
        
<script type="text/javascript" src="//newsharecounts.s3-us-west-2.amazonaws.com/nsc.js"></script>

    
</body>
</html>

